
# ğŸ“„ Policy Question Answering Assistant (RAG)

A **Retrieval-Augmented Generation (RAG)** system.  
The system answers questions about company policy documents using **semantic retrieval + Google Gemini**, with a strong focus on **prompt engineering, hallucination avoidance, and evaluation**.
---
# Live app link : https://rag-policy-system-1.streamlit.app/
---

## ğŸš€ Features

- Loads real policy documents from disk (`sample_policies/`)
- Cleans and chunks documents (512 characters per chunk)
- Semantic search using Sentence Transformers + ChromaDB
- Answer generation using **Google Gemini (Free Tier)**
- Prompt iteration (baseline vs improved prompt)
- Explicit hallucination control
- Automatic evaluation with results saved to `evaluation_results.json`
- CLI demo + optional Streamlit UI

---

## ğŸ§  Architecture Overview

```
User Question
      â†“
SentenceTransformer Embedding
      â†“
ChromaDB (Vector Search)
      â†“
Top-k Relevant Chunks
      â†“
Prompt + Context
      â†“
Google Gemini
      â†“
Grounded Answer + Confidence + Sources
```

---

## ğŸ“ Project Structure

```
rag-policy-system/
â”œâ”€â”€ rag_system.py              # Core RAG pipeline + evaluation
â”œâ”€â”€ demo.py                    # CLI demo
â”œâ”€â”€ app.py                     # Streamlit UI (bonus)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ PROMPT_COMPARISON.md
â”œâ”€â”€ QUICK_REFERENCE.md
â”œâ”€â”€ evaluation_results.json    # Auto-generated
â”œâ”€â”€ .env                       # API key (not committed)
â””â”€â”€ sample_policies/
    â”œâ”€â”€ refund_policy.txt
    â”œâ”€â”€ shipping_policy.txt
    â””â”€â”€ cancellation_policy.txt
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create virtual environment
```bash
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set API key

Create a `.env` file:
```env
GOOGLE_API_KEY=your_gemini_api_key_here
```

Get your key from: https://makersuite.google.com/app/apikey

---

## â–¶ï¸ Running the Project

### Run evaluation (creates JSON output)
```bash
python rag_system.py
```

### Run CLI demo
```bash
python demo.py
```

### Run Streamlit UI (bonus)
```bash
streamlit run app.py
```

---

## ğŸ§ª Evaluation

- 8 questions tested
- Answerable / Partial / Unanswerable
- Manual rubric: âœ… PASS / âš ï¸ PARTIAL / âŒ FAIL
- Results saved automatically to:

```
evaluation_results.json
```

### Design Choice
The system intentionally favors **hallucination avoidance over aggressive confidence**, resulting in some answers marked as *Partial*.  
This trade-off ensures safety and correctness.

---

## ğŸ” Prompt Engineering

- **V1**: Basic context injection
- **V2**: Structured prompt with:
  - Explicit grounding rules
  - Confidence scoring
  - Source attribution
  - Clear handling of missing information

See `PROMPT_COMPARISON.md` for details.

---

## ğŸ”® Future Improvements

- Reranking retrieved chunks
- JSON schema validation
- Multi-document answer synthesis
- Persistent vector store
- Better confidence calibration

---

## âœ… What Iâ€™m Most Proud Of

Designing a **safe, grounded RAG system** that avoids hallucinations and clearly communicates uncertainty through evaluation.

## ğŸ”§ What Iâ€™d Improve Next

Improve confidence calibration and add reranking to boost answer completeness without sacrificing safety.
